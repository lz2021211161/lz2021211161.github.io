<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>HTTP基础（上）</title>
    <link href="/2024/11/10/HTTP%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/"/>
    <url>/2024/11/10/HTTP%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h1 id="HTTP基础"><a href="#HTTP基础" class="headerlink" title="HTTP基础"></a>HTTP基础</h1><h2 id="HTTP基本概念"><a href="#HTTP基本概念" class="headerlink" title="HTTP基本概念"></a>HTTP基本概念</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>HTTP全名为超文本传输协议，也就是<strong>H</strong>yper<strong>T</strong>ext <strong>T</strong>ransfer <strong>P</strong>rotocol。</p><p>可以拆解为三个部分：</p><ol><li>超文本</li></ol><p>​指HTTP传输的内容是超文本。超文本就是指超越了普通文本的文本。普通文本包括简单的字符文字，图片，视频等。而超文本在包含文本内容的同时还包括了<strong>超链接</strong>，即可以从一个超文本跳转到另一个超文本。</p><p>​HTML就是最常见的超文本。它本身只是纯文字文件，但内部用很多标签定义了图片、视频等的链接，再经过浏览器的解释，呈现给我们的就是一个文字、有画面的网页了。</p><ol start="2"><li>传输</li></ol><p>​此处的传输很好理解，就是使得一些内容从A到B，或从B到A。其中包含两个要点：1. HTTP是<strong>双向协议</strong>。我们冲浪时的浏览器和网站服务器可以各自作为请求方和应答方以进行信息传输。2. 数据在传输中间会经历<strong>中转和接力</strong>。中间路由也需要遵从HTTP协议，只要不打扰基本的数据传输，就可以添加任意额外的东西。</p><img src="/2024/11/10/HTTP%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/5-%E8%AF%B7%E6%B1%82%E5%BA%94%E7%AD%94.png" class="" title="请求 - 应答"><ol start="3"><li>协议</li></ol><p>​计算机网络中的协议和生活中签订的协议本质上是相同的。</p><p>​协，指必须有两个以上的参与者。议，指对参与者的一种行为规定和规范。</p><p>综合起来，超文本传输协议可以描述为：<br><strong>HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。</strong></p><h3 id="常见的状态码"><a href="#常见的状态码" class="headerlink" title="常见的状态码"></a>常见的状态码</h3><img src="/2024/11/10/HTTP%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png" class="" title="五大类 HTTP 状态码"><h3 id="HTTP常见字段"><a href="#HTTP常见字段" class="headerlink" title="HTTP常见字段"></a>HTTP常见字段</h3><ul><li>Host字段：客户端发送请求时，用来指定服务器的域名（<a href="http://www.a.com).可以通过该字段区分同一个服务器上的不同网站资源./">www.A.com）。可以通过该字段区分同一个服务器上的不同网站资源。</a></li><li>Content-Length 字段：服务器返回数据时包含该字段，表明本次回应的数据长度。</li></ul><blockquote><p>大家应该都知道 HTTP 是基于 TCP 传输协议进行通信的，而使用了 TCP 传输协议，就会存在一个“粘包”的问题，<strong>HTTP 协议通过设置回车符、换行符作为 HTTP header 的边界，通过 Content-Length 字段作为 HTTP body 的边界，这两个方式都是为了解决“粘包”的问题</strong>。</p></blockquote><ul><li><p>Connection 字段：该字段最常用于客户端要求服务器使用HTTP 长连接机制，以便其他请求复用（Connection: Keep-Alive）。HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。开启了 HTTP Keep-Alive 机制后， 连接就不会中断，而是保持连接。当客户端发送另一个请求时，它会使用同一个连接，一直持续到客户端或服务器端提出断开连接。</p></li><li><p>Content-Type 字段：用于服务器回应时，告诉客户端，本次数据是什么格式。</p></li><li><p>Content-Encoding 字段：说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式。</p></li></ul><h2 id="GET-和-POST"><a href="#GET-和-POST" class="headerlink" title="GET 和 POST"></a>GET 和 POST</h2><h3 id="有什么区别？"><a href="#有什么区别？" class="headerlink" title="有什么区别？"></a>有什么区别？</h3><p><strong>GET 的语义是从服务器获取指定的资源</strong>，这个资源可以是静态的文本、页面、图片、视频等。GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符。而且浏览器会对 URL 的长度有限制（HTTP协议本身对 URL长度并没有做任何规定）。 </p><p><strong>POST 的语义是根据请求负荷（报文body）对指定的资源做出处理</strong>，具体的处理方式视资源类型而不同。</p><h3 id="GET-和-POST-方法都是安全且幂等的吗？"><a href="#GET-和-POST-方法都是安全且幂等的吗？" class="headerlink" title="GET 和 POST 方法都是安全且幂等的吗？"></a>GET 和 POST 方法都是安全且幂等的吗？</h3><p>先说明下安全和幂等的概念：</p><ul><li><p>在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。</p></li><li><p>所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。</p></li></ul><p>根据以上的定义来分析：</p><ul><li><strong>GET 方法是安全且幂等的</strong>。故可以对GET请求的数据做缓存。</li><li>POST 是新增和提交数据的操作，会修改服务器上的资源，所以<strong>不安全</strong>且<strong>不幂等</strong>。</li></ul><p>如果「安全」放入概念是指信息是否会被泄漏的话，虽然 POST 用 body 传输数据，而 GET 用 URL 传输，这样数据会在浏览器地址拦容易看到，但是并不能说 GET 不如 POST 安全的。</p><p>因为 HTTP 传输的内容都是明文的，虽然在浏览器地址拦看不到 POST 提交的 body 数据，但是只要抓个包就都能看到了。</p><p>要避免传输过程中数据被窃取，就要使用 HTTPS 协议</p><p>当然并没有规定GET 请求不能带body，POST 请求不能在URL 中加参数。只是如果操作是规范的，则以上操作是没有必要的。</p><h2 id="HTTP缓存技术"><a href="#HTTP缓存技术" class="headerlink" title="HTTP缓存技术"></a>HTTP缓存技术</h2><h3 id="如何实现？"><a href="#如何实现？" class="headerlink" title="如何实现？"></a>如何实现？</h3><p>对于一些具有重复性的 HTTP 请求，我们可以把这对「请求-响应」的数据都<strong>缓存在本地</strong>，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了，这样的话 HTTP&#x2F;1.1 的性能肯定肉眼可见的提升。</p><p>HTTP 缓存有两种实现方式，分别是<strong>强制缓存和协商缓存</strong>。</p><h3 id="强制缓存"><a href="#强制缓存" class="headerlink" title="强制缓存"></a>强制缓存</h3><p>强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。</p><p>如下图中，返回的是 200 状态码，但在 size 项中标识的是 from disk cache，就是使用了强制缓存。</p><img src="/2024/11/10/HTTP%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/1cb6bc37597e4af8adfef412bfc57a42.png" class="" title="img"><p>强制缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：</p><ul><li><p><code>Cache-Control</code>， 是一个相对时间；</p></li><li><p><code>Expires</code>，是一个绝对时间；</p></li></ul><p><strong>Cache-Control 的优先级高于 Expires</strong></p><ul><li><p>当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；</p></li><li><p>浏览器再次请求访问服务器中的该资源时，会先<strong>通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期</strong>，如果没有，则使用该缓存，否则重新请求服务器；</p></li><li><p>服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。</p></li></ul><h3 id="协商缓存"><a href="#协商缓存" class="headerlink" title="协商缓存"></a>协商缓存</h3><p><strong>协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存</strong>。</p><img src="/2024/11/10/HTTP%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/%E7%BC%93%E5%AD%98etag.png" class="" title="img"><p>协商缓存可以基于两种头部来实现。</p><p>第一种：请求头部中的 <code>If-Modified-Since</code> 字段与响应头部中的<code>Last-Modified</code> 字段实现。服务器先发送带<code>Last-Modified</code> 的响应，客户端收到后会发带 <code>If-Modified-Since</code> 的请求，服务器会对比两个时间来判断本地缓存是否有效。</p><p>第二种：请求头部中的 <code>If-None-Match</code> 字段与响应头部中的 <code>ETag</code> 字段。ETag可以唯一标识响应资源。服务器通过客户端传来的ETag来比较看是否变化。</p><p>如果同时携带ETag和Last-Modified字段，<strong>Etag 的优先级更高</strong>，也就是服务端先会判断 Etag 是否变化了，如果 Etag 有变化就不用在判断 Last-Modified 了，如果 Etag 没有变化，然后再看 Last-Modified。</p><p>这是因为 ETag 主要能解决 Last-Modified 几个比较难以解决的问题：</p><ol><li>在没有修改文件内容情况下文件的最后修改时间可能也会改变，这会导致客户端认为这文件被改动了，从而重新请求；</li><li>可能有些文件是在秒级以内修改的，<code>If-Modified-Since</code> 能检查到的粒度是秒级的，使用 Etag就能够保证这种需求下客户端在 1 秒内能刷新多次；</li><li>有些服务器不能精确获取文件的最后修改时间。</li></ol><p>注意，<strong>协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求</strong>。</p><p>整体工作流程：</p><img src="/2024/11/10/HTTP%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/http%E7%BC%93%E5%AD%98.png" class="" title="img"><h2 id="HTTP特性"><a href="#HTTP特性" class="headerlink" title="HTTP特性"></a>HTTP特性</h2><p>HTTP 常见到版本有 HTTP&#x2F;1.1，HTTP&#x2F;2.0，HTTP&#x2F;3.0，不同版本的 HTTP 特性是不一样的。</p><h3 id="HTTP-1-1-的优点"><a href="#HTTP-1-1-的优点" class="headerlink" title="HTTP&#x2F;1.1 的优点"></a>HTTP&#x2F;1.1 的优点</h3><p>HTTP 最突出的优点是「简单、灵活和易于扩展、应用广泛和跨平台」。</p><ul><li><p>简单</p><p>HTTP 基本的报文格式就是 <code>header + body</code>，头部信息也是 <code>key-value</code> 简单文本的形式</p></li><li><p>灵活和易于扩展</p><p>HTTP 协议里的各类请求方法、URI&#x2F;URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员<strong>自定义和扩充</strong>。</p></li></ul><p>​同时 HTTP 由于是工作在应用层（ <code>OSI</code> 第七层），则它<strong>下层可以随意变化</strong>，比如：</p><p>​HTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL&#x2F;TLS 安全传输层；</p><p>​HTTP&#x2F;1.1 和 HTTP&#x2F;2.0 传输协议使用的是 TCP 协议，而到了 HTTP&#x2F;3.0 传输协议改用了 UDP 协议。</p><ul><li>应用广泛和跨平台</li></ul><h3 id="HTTP-1-1-的缺点"><a href="#HTTP-1-1-的缺点" class="headerlink" title="HTTP&#x2F;1.1 的缺点"></a>HTTP&#x2F;1.1 的缺点</h3><p>HTTP 协议里有优缺点一体的<strong>双刃剑</strong>，分别是「无状态、明文传输」，同时还有一大缺点「不安全」。</p><ul><li><p>无状态</p><p>无状态的<strong>好处</strong>，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。</p></li></ul><p>​无状态的<strong>坏处</strong>，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。</p><p>​例如登录-&gt;添加购物车-&gt;下单-&gt;结算-&gt;支付，这系列操作都要知道用户的身份才行。但服务器不知道这些请求是有关联的，每次都要问一遍身份信息。</p><p>​对于无状态的问题，解法方案有很多种，其中比较简单的方式用 <strong>Cookie</strong> 技术。</p><p>​<code>Cookie</code> 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。</p><p>​相当于，<strong>在客户端第一次请求后，服务器会下发一个装有客户信息的「小贴纸」，后续客户端请求服务器的时候，带上「小贴纸」，服务器就能认得了了</strong></p><ul><li>明文传输</li></ul><p>​明文传输的好处是对于编程者可以方便的进行抓包和解析，十分便利</p><p>​但同时在传输的漫长过程中，该消息也能随时被别人截取，毫无隐私可言。</p><ul><li>不安全</li></ul><h3 id="性能如何"><a href="#性能如何" class="headerlink" title="性能如何"></a>性能如何</h3><p>HTTP 协议是基于 <strong>TCP&#x2F;IP</strong>，并且使用了「<strong>请求 - 应答</strong>」的通信模式</p><ol><li>长连接</li></ol><p>​早期 HTTP&#x2F;1.0 性能上的一个很大的问题，那就是每发起一个请求，都要新建一次 TCP 连接（三次握手），而且是串行请求，做了无谓的 TCP 连接建立和断开，增加了通信开销。</p><p>​HTTP&#x2F;1.1 提出了<strong>长连接</strong>的通信方式，也叫持久连接。</p><img src="/2024/11/10/HTTP%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/16-%E7%9F%AD%E8%BF%9E%E6%8E%A5%E4%B8%8E%E9%95%BF%E8%BF%9E%E6%8E%A5.png" class="" title="短连接与长连接"><ol start="2"><li>管道网络传输</li></ol><p>​HTTP&#x2F;1.1 采用了长连接的方式，这使得管道（pipeline）网络传输成为了可能。</p><p>​即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以<strong>减少整体的响应时间。</strong></p><p>​举例来说，客户端需要请求两个资源。以前的做法是，在同一个 TCP 连接里面，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。那么，管道机制则是允许浏览器同时发出 A 请求和 B 请求，如下图：</p><img src="/2024/11/10/HTTP%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/17-%E7%AE%A1%E9%81%93%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93.png" class="" title="管道网络传输"><p>但是<strong>服务器必须按照接收请求的顺序发送对这些管道化请求的响应</strong>。</p><p>如果服务端在处理 A 请求时耗时比较长，那么后续的请求的处理都会被阻塞住，这称为「队头堵塞」。<strong>HTTP&#x2F;1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞</strong>。</p><p>实际上 HTTP&#x2F;1.1 管道化技术不是默认开启，而且浏览器基本都没有支持，所以<strong>后面所有文章讨论 HTTP&#x2F;1.1 都是建立在没有使用管道化的前提</strong>。</p><ol start="3"><li>队头阻塞</li></ol><p>​「请求 - 应答」的模式会造成 HTTP 的性能问题。</p><p>​因为当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据，这也就是「<strong>队头阻塞</strong>」，好比上班的路上塞车。</p><img src="/2024/11/10/HTTP%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/18-%E9%98%9F%E5%A4%B4%E9%98%BB%E5%A1%9E.png" class="" title="队头阻塞"><p>但HTTP&#x2F;1.1 还是有性能瓶颈</p><ul><li><p>请求 &#x2F; 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 <code>Body</code> 的部分；</p></li><li><p>请求只能从客户端开始，服务器只能被动响应。</p></li></ul><h3 id="HTTP-2-的优化"><a href="#HTTP-2-的优化" class="headerlink" title="HTTP&#x2F;2 的优化"></a>HTTP&#x2F;2 的优化</h3><p>HTTP&#x2F;2 协议是基于 HTTPS 的，所以 HTTP&#x2F;2 的安全性也是有保障的。</p><img src="/2024/11/10/HTTP%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/25-HTTP2.jpeg" class="" title="HTT&#x2F;1 ~ HTTP&#x2F;2"><p>HTTP&#x2F;2 相比 HTTP&#x2F;1.1 性能上的改进：</p><ol><li><p>头部压缩</p><p>HTTP&#x2F;2 会<strong>压缩头</strong>（Header）。如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你<strong>消除重复的部分</strong>。</p><p>这就是所谓的 <code>HPACK</code> 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就<strong>提高速度</strong>了。</p></li><li><p>二进制格式</p><p>HTTP&#x2F;2 不再像 HTTP&#x2F;1.1 里的纯文本形式的报文，而是全面采用了<strong>二进制格式</strong>，头信息和数据体都是二进制，并且统称为帧（frame）：<strong>头信息帧（Headers Frame）和数据帧（Data Frame）</strong>。</p><p>这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这<strong>增加了数据传输的效率</strong>。</p><p>比如状态码 200 ，在 HTTP&#x2F;1.1 是用 ‘2’’0’’0’ 三个字符来表示（二进制：00110010 00110000 00110000），共用了 3 个字节</p><p>在 HTTP&#x2F;2 对于状态码 200 的二进制编码是 10001000，只用了 1 字节就能表示，相比于 HTTP&#x2F;1.1 节省了 2 个字节。（最前面的 1 标识该 Header 是静态表中已经存在的 KV。在静态表里，“:status: 200 ok” 静态表编码是 8，二进制即是 1000。）</p></li><li><p>并发传输</p><p>针对HTTP&#x2F;1.1 的队头阻塞问题，HTTP&#x2F;2 引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接。</p><p>1 个 TCP 连接包含多个 Stream，Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP&#x2F;1 中的请求或响应，由 HTTP 头部和包体构成。Message 里包含一条或者多个 Frame，由 HTTP 头部和包体构成。Message 里包含一条或者多个 Frame，</p><p><strong>针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过</strong> <strong>Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP&#x2F;2 可以并行交错地发送请求和响应</strong>。</p></li><li><p>服务器推送</p><p>服务端不再是被动地响应，可以<strong>主动</strong>向客户端发送消息。</p><p>客户端和服务器<strong>双方都可以建立 Stream</strong>， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。</p></li></ol><img src="/2024/11/10/HTTP%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/push.png" class="" title="img"><p>​在 HTTP&#x2F;2 中，客户端在访问 HTML 时，服务器可以直接主动推送 CSS 文件</p><p>HTTP&#x2F;2仍然存在队头阻塞问题：</p><p>只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。</p><p><strong>HTTP&#x2F;2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP&#x2F;2 应用层才能从内核中拿到数据，这就是 HTTP&#x2F;2 队头阻塞问题。</strong></p><p>所以，一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的<strong>所有的 HTTP 请求都必须等待这个丢了的包被重传回来</strong>。</p><h3 id="HTTP-3的优化"><a href="#HTTP-3的优化" class="headerlink" title="HTTP&#x2F;3的优化"></a>HTTP&#x2F;3的优化</h3><p><strong>HTTP&#x2F;3 把 HTTP 下层的 TCP 协议改成了 UDP！</strong></p><p>UDP 是不可靠传输，但基于 UDP 的 <strong>QUIC 协议</strong> 可以实现类似 TCP 的可靠性传输。</p><p>QUIC 有以下 3 个特点：</p><ol><li><p>无队头阻塞</p><p>QUIC 有自己的一套机制可以保证传输的可靠性的。<strong>当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题</strong>。这与 HTTP&#x2F;2 不同，HTTP&#x2F;2 只要某个流中的数据包丢失了，其他流也会因此受影响。</p><p>QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。</p></li></ol><img src="/2024/11/10/HTTP%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/quic%E6%97%A0%E9%98%BB%E5%A1%9E.jpeg" class="" title="img"><ol start="2"><li><p>更快的连接建立</p><p>对于 HTTP&#x2F;1 和 HTTP&#x2F;2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。</p><p>HTTP&#x2F;3 在传输数据前虽然需要 QUIC 协议握手，但是这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。</p><p>QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS&#x2F;1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，如下图：</p><img src="/2024/11/10/HTTP%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/28-HTTP3%E4%BA%A4%E4%BA%92%E6%AC%A1%E6%95%B0.jpeg" class="" title="TCP HTTPS（TLS&#x2F;1.3） 和 QUIC HTTPS"><p>甚至，在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。HTTP&#x2F;3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT</p><img src="/2024/11/10/HTTP%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/4cad213f5125432693e0e2a512c2d1a1-20230309231022316.png" class="" title="img"></li><li><p>连接建立</p><p>基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。</p><p>那么<strong>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接</strong>。</p><p>而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<strong>连接 ID</strong> 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>Network</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Network</tag>
      
      <tag>HTTP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>OS-ExecuteEfficiency</title>
    <link href="/2024/11/08/OS-ExecuteEfficiency/"/>
    <url>/2024/11/08/OS-ExecuteEfficiency/</url>
    
    <content type="html"><![CDATA[<h1 id="如何提升代码的执行效率"><a href="#如何提升代码的执行效率" class="headerlink" title="如何提升代码的执行效率"></a>如何提升代码的执行效率</h1><h2 id="CPU-Cache"><a href="#CPU-Cache" class="headerlink" title="CPU Cache"></a>CPU Cache</h2><p>在之前的文章中，我们已经介绍了操作系统的分级内存体系，其中总结了不同的存储器的读写效率，以及CPU读写数据的方式。</p><p>我们可以得知，如果代码中的数据能够直接从快速存储器中读取到，而不是要从遥远的硬盘逐级调入，则能够大幅提升代码的执行效率。</p><p>要尝试利用好CPU Cache，我们首先要了解其内部结构及读写过程：</p><p>CPU Cache是由很多Cache Line组成的，Cache  Line 是 CPU 从内存读取数据的基本单位，Cache Line 是由各种标志（Tag）+ 数据块（Data Block）组成，CPU Cache 的数据是从内存中读取过来的，它是以Cache Line 大小为单位读取数据的</p><img src="/2024/11/08/OS-ExecuteEfficiency/Cache%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" class="" title="img"><p>我们不妨假设L1 Cache Line 大小是 64 字节，也就意味着 <strong>L1 Cache 一次载入数据的大小是 64 字节</strong>。</p><p>比如，有一个 <code>int array[100]</code> 的数组，当载入 <code>array[0]</code> 时，由于这个数组元素的大小在内存只占 4 字节，不足 64 字节，CPU 就会<strong>顺序加载</strong>数组元素到 <code>array[15]</code>，意味着 <code>array[0]~array[15]</code>数组元素都会被缓存在 CPU Cache 中了，因此当下次访问这些数组元素时，会直接从 CPU Cache 读取，而不用再从内存中读取，大大提高了 CPU 读取数据的性能。</p><p>不同的映射逻辑决定了内存和CPU Cache 数据的对应关系，先来讲一下直接映射。</p><p>前面，我们提到 CPU 访问内存数据时，是一小块一小块数据读取的，一般是64字节。在内存中，这一块的数据我们称为<strong>内存块（Block）</strong>，读取的时候我们要拿到数据所在内存块的地址。</p><p>对于直接映射 Cache 采用的策略，就是把内存块的地址始终「映射」在一个 CPU Cache Line（缓存块） 的地址，至于映射关系实现方式，则是使用「取模运算」，取模运算的结果就是内存块地址对应的 CPU Cache Line（缓存块） 的地址。</p><p>使用取模方式映射，会出现多个内存块对应同一个 CPU Cache Line上的情况。因此，为了区别不同的内存块，在对应的 CPU Cache Line 中我们还会存储一个<strong>组标记（Tag）</strong>。这个组标记会记录当前 CPU Cache Line 中存储的数据对应的内存块，我们可以用这个组标记来区分不同的内存块。</p><p>除了组标记信息外，CPU Cache Line 还有两个信息：</p><ul><li>一个是，从内存加载过来的实际存放<strong>数据（Data）</strong>。</li><li>另一个是，<strong>有效位（Valid bit）</strong>，它是用来标记对应的 CPU Cache Line  中的数据是否是有效的，如果有效位是 0，无论 CPU Cache Line 中是否有数据，CPU 都会直接访问内存，重新加载数据。</li></ul><p>CPU 在从 CPU Cache 读取数据的时候，并不是读取 CPU Cache Line 中的整个数据块，而是读取 CPU 所需要的一个数据片段，这样的数据统称为一个<strong>字（Word）</strong>。需要一个<strong>偏移量（Offset）</strong>来标识该读取的字在CPU Cache Line 中的位置。</p><p>因此，一个内存的访问地址，包括<strong>组标记、CPU Cache Line 索引、偏移量</strong>这三种信息，于是 CPU 就能通过这些信息，在 CPU Cache 中找到缓存的数据。而对于 CPU Cache 里的数据结构，则是由<strong>索引 + 有效位 + 组标记 + 数据块</strong>组成。</p><img src="/2024/11/08/OS-ExecuteEfficiency/%E7%9B%B4%E6%8E%A5Cache%E6%98%A0%E5%B0%84.png" class="" title="img"><p>全相联映射：</p><p>将主存中的块号和块内容一起存在Cache Line 中，其中块地址存于 cache 行的标记(tag)部分中。这种带全部块地址一起保存的方法，可使主存的一个块直接复制到 cache 中的任意一行上，非常灵活。</p><p>其检索过程为：将指令中的块号与Cache 中所有行的tag同时进行比较，若块号命中，则按偏移量从Cache 中读取指定字，若未命中，则按主存地址从主存中读取这个字。</p><img src="/2024/11/08/OS-ExecuteEfficiency/image-20241109144432994.png" class="" title="image-20241109144432994"><p>组相联映射：</p><p>全相联映射和直接映射两种方式的优缺点正好相反。从存放位置的灵活性和命中率来看，前者为优；从比较器电路简单及硬件投资来说，后者为佳。而组相联映射方式是前两种方式的折中方案，它适度地兼顾了二者的优点又尽量避免二者的缺点，因此被普遍采用。</p><p>在直接映射方式中，每个区第 <em>i</em> 块只能映射到 cache 唯一的第 <em>i</em> 行，冲突的概率可能会很大。而在组相联映射方式中，每个区第 <em>i</em> 块可以映射到第 <em>i</em> 组的 <em>v</em> 行中(图中 <em>v</em>&#x3D;2)，而且在 <em>v</em> 行中可以自由选择空余的行。</p><p>当 CPU 给定一个内存地址访问 cache 时，首先用 <em>d</em> 位区内块号找到 cache 的相应组，然后将主存地址高 <em>s</em>–<em>d</em> 位区号部分与该组 <em>v</em> 行中的所有标记同时进行比较。哪行的标记与之相符，哪行即命中。此后再以内存地址的 <em>w</em> 位字地址部分检索此行的具体字，并完成所需要求的存取操作。如果此组没有一行的标记与之相符，即 cache 未命中，此时需按主存地址访问主存</p><img src="/2024/11/08/OS-ExecuteEfficiency/image-20241109145104577.png" class="" title="image-20241109145104577"><img src="/2024/11/08/OS-ExecuteEfficiency/image-20241109145119120.png" class="" title="image-20241109145119120"><h2 id="如何写入让CPU效率更高的代码？"><a href="#如何写入让CPU效率更高的代码？" class="headerlink" title="如何写入让CPU效率更高的代码？"></a>如何写入让CPU效率更高的代码？</h2><p>了解了CPU Cache 的运行模式后，我们要回归主题，探究如何写出让CPU 处理效率更高的代码。</p><p>关键的方法就是尽力增加<strong>缓存命中</strong>的概率。</p><p>于是，「如何写出让 CPU 跑得更快的代码？」这个问题，可以改成「如何写出 CPU 缓存命中率高的代码？」。</p><p> L1 Cache 分为「数据缓存」和「指令缓存」，这是因为 CPU 会分别处理数据和指令，比如 <code>1+1=2</code> 这个运算，<code>+</code> 就是指令，会被放在「指令缓存」中，而输入数字 <code>1</code> 则会被放在「数据缓存」里。</p><p>因此，<strong>我们要分开来看「数据缓存」和「指令缓存」的缓存命中率</strong>。</p><h3 id="如何提升数据缓存的命中率"><a href="#如何提升数据缓存的命中率" class="headerlink" title="如何提升数据缓存的命中率?"></a>如何提升数据缓存的命中率?</h3><p>对于如下两种遍历二维数组的方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">for</span> (i=<span class="hljs-number">0</span>; i&lt;N; i++) &#123;<br>    <span class="hljs-keyword">for</span> (j=<span class="hljs-number">0</span>; j&lt;N; j++) &#123;<br>        array[i][j] = <span class="hljs-number">0</span>;<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">for</span> (j=<span class="hljs-number">0</span>; j&lt;N; j++) &#123;<br>    <span class="hljs-keyword">for</span> (i=<span class="hljs-number">0</span>; i&lt;N; i++) &#123;<br>        array[j][i] = <span class="hljs-number">0</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>经过测试，形式一 <code>array[i][j]</code> 执行时间比形式二 <code>array[j][i]</code> 快好几倍。</p><p>这种差距是由于在内存中二维数组的保存方式是以行连续的。当 CPU 访问 <code>array[0][0]</code> 时，由于该数据不在 Cache 中，于是会「顺序」把跟随其后的 3 个元素从内存中加载到 CPU Cache，这样当 CPU 访问后面的 3 个数组元素时，就能在 CPU Cache 中成功地找到数据，这意味着缓存命中率很高，缓存命中的数据不需要访问内存，这便大大提高了代码的性能。</p><p>CPU一次从内存中加载到CPU Cache中的内容与CPU Cache Line 大小有关，可以在 Linux 里通过 <code>coherency_line_size</code> 配置查看 它的大小，通常是 64 个字节。</p><p>那么当访问 <code>array[0][0]</code> 时，由于该元素不足 64 字节，于是就会往后<strong>顺序</strong>读取 <code>array[0][0]~array[0][15]</code> 到 CPU Cache 中。</p><p><strong>因此，遇到这种遍历数组的情况时，按照内存布局顺序访问，将可以有效的利用</strong> <strong>CPU Cache 带来的好处，这样我们代码的性能就会得到很大的提升，</strong></p><h3 id="如何提升指令缓存的命中率？"><a href="#如何提升指令缓存的命中率？" class="headerlink" title="如何提升指令缓存的命中率？"></a>如何提升指令缓存的命中率？</h3><p>对于如下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">// 1. 数组遍历</span><br><span class="hljs-keyword">for</span> (i=<span class="hljs-number">0</span>; i&lt;N; i++) &#123;<br>    <span class="hljs-keyword">if</span> (array[i] &lt; <span class="hljs-number">50</span>)<br>        array[i] = <span class="hljs-number">0</span>;<br>&#125;<br><br><span class="hljs-comment">// 2. 数组排序</span><br>Arrays.sort(array);<br></code></pre></td></tr></table></figure><p>是先遍历再排序速度快，还是先排序再遍历速度快呢？</p><p>在回答这个问题之前，我们先了解 CPU 的<strong>分支预测器</strong>。对于 if 条件语句，意味着此时至少可以选择跳转到两段不同的指令执行，也就是 if 还是 else 中的指令。那么，<strong>如果分支预测可以预测到接下来要执行 if 里的指令，还是 else 指令的话，就可以「提前」把这些指令放在指令缓存中，这样 CPU 可以直接从 Cache 读取到指令，于是执行速度就会很快</strong>。</p><p>因此，先排序再遍历速度会更快，这是因为排序之后，数字是从小到大的，那么前几次循环命中 <code>if &lt; 50</code> 的次数会比较多，于是分支预测就会缓存 <code>if</code> 里的 <code>array[i] = 0</code> 指令到 Cache 中，后续 CPU 执行该指令就只需要从 Cache 读取就好了。</p><p>如果你肯定代码中的 <code>if</code> 中的表达式判断为 <code>true</code> 的概率比较高，我们可以使用显示分支预测工具，比如在 C&#x2F;C++ 语言中编译器提供了 <code>likely</code> 和 <code>unlikely</code> 这两种宏，如果 <code>if</code> 条件为 <code>ture</code> 的概率大，则可以用 <code>likely</code> 宏把 <code>if</code> 里的表达式包裹起来，反之用 <code>unlikely</code> 宏。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-keyword">if</span> (likely(a == <span class="hljs-number">1</span>)) &#123;<br>    <span class="hljs-comment">// ...</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-comment">// ...</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="如何提升多核CPU的缓存命中率？"><a href="#如何提升多核CPU的缓存命中率？" class="headerlink" title="如何提升多核CPU的缓存命中率？"></a>如何提升多核CPU的缓存命中率？</h3><p>在单核 CPU，虽然只能执行一个线程，但是操作系统给每个线程分配了一个时间片，时间片用完了，就调度下一个线程，于是各个线程就按时间片交替地占用 CPU，从宏观上看起来各个线程同时在执行。</p><p>而现代 CPU 都是多核心的，线程可能在不同 CPU 核心来回切换执行，这对 CPU Cache 不是有利的，虽然 L3 Cache 是多核心之间共享的，但是 L1 和 L2 Cache 都是每个核心独有的，<strong>如果一个线程在不同核心来回切换，各个核心的缓存命中率就会受到影响</strong>，相反如果线程都在同一个核心上执行，那么其数据的 L1 和 L2 Cache 的缓存命中率可以得到有效提高，缓存命中率高就意味着 CPU 可以减少访问内存的频率。</p><p>当有多个同时执行「计算密集型」的线程，为了防止因为切换到不同的核心，而导致缓存命中率下降的问题，我们可以把<strong>线程绑定在某一个 CPU 核心上</strong></p><p>在 Linux 上提供了 <code>sched_setaffinity</code> 方法，来实现将线程绑定到某个 CPU 核心这一功能。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs Linux">#define _GNU_SOURCE<br>#include &lt;Sched.h&gt;<br><br>int sched_setaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>OS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>OS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Network-Linux</title>
    <link href="/2024/11/08/Network-Linux/"/>
    <url>/2024/11/08/Network-Linux/</url>
    
    <content type="html"><![CDATA[<h1 id="Linux系统是如何收发网络包的？"><a href="#Linux系统是如何收发网络包的？" class="headerlink" title="Linux系统是如何收发网络包的？"></a>Linux系统是如何收发网络包的？</h1><h2 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h2><p>OSI网络模型共有七层，由国际标准化组织制定。但七层的分层过于复杂，故该模型一般只用于概念和理论，并没有实际的实现方案。</p><p>常见的分层模型为TCP&#x2F;IP网络模型，共包含四层，分别是应用层、传输层、网络层和网络接口层，Linux系统同样也采用了TCP&#x2F;IP网络模型来实现协议栈。</p><p>简要介绍一下TCP&#x2F;IP模型：</p><ul><li>应用层：负责向用户提供应用程序，如HTTP、DNS等</li><li>传输层：负责端到端的通信，如TCP、UDP等</li><li>网络层：负责网络包的封装、分片、路由、转发，如IP、ICMP等</li><li>网络接口层：负责网络包在物理网络中的传输，如网络包的封帧、MAC寻址、差错校验以及通过网卡传输帧等</li></ul><p>TCP&#x2F;IP模型和OSI模型间各层的对应关系如下图：</p><img src="/2024/11/08/Network-Linux/OSI%E4%B8%8ETCP.png" class="" title="img"><p>这里提一下常说的七层和四层负载均衡，指的是OSI七层模型中的应用层和传输层。</p><blockquote><p>负载均衡：通俗一点理解就是尽可能将网络流量平均分发到多个服务器上，以提高系统整体的响应速度和可用性。</p><p>可以分为两类：硬件负载均衡和软件负载均衡</p><ul><li><p>硬件负载均衡：一般是在定制的处理器上运行独立负载均衡服务器，问题就是贵</p></li><li><p>软件负载均衡：从软件层面实现负载均衡，比较常见的是OSI模型中四层和七层的负载均衡。</p><ul><li><p>七层负载均衡：根据访问用户的HTTP请求头、URL信息将请求转发到特定的主机</p><ul><li><p>DNS重定向</p><p>大型网站一般用DNS负载均衡作为第一级负载均衡手段，然后在内部使用其他方法做第二级负载均衡。</p><p>DNS，域名解析服务，设计为一个树形结构的分布式应用，自上而下依次为：根域名服务器，一级域名服务器，二级域名服务器…本地域名服务器。</p><p>DNS工作流程是一个逆向的递归流程，DNS客户端依次请求本地DNS服务器，上一级DNS服务器…根DNS服务器，一旦命中，再进行递归查询。为了减少查询次数，每一级DNS服务器都会设置DNS查询缓存。</p><p>DNS负载均衡的原理就是：基于DNS查询缓存，按照负载情况返回不同服务器的IP地址。</p><img src="/2024/11/08/Network-Linux/580a887aab6af82ab03d7f00cd319ef8.jpeg" class="" title="img"></li><li><p>HTTP重定向</p><p>原理：根据用户的HTTP请求计算出真实的服务器地址，将该服务器地址写入HTTP重定向响应中，返回给浏览器，由浏览器进行访问</p><img src="/2024/11/08/Network-Linux/a8c0240dadeb0500d70168a8720d2062.png" class="" title="img"></li><li><p>反向代理负载均衡</p><p>是指以代理服务器来接受网络请求，然后将请求转发给内网中的服务器，并将从内网服务器上得到的结果返回给网络请求的客户端。</p><p>正向代理：发生在客户端，是由用户主动发起的。翻墙软件是典型的正向代理，客户端通过主动访问代理服务器，让代理服务器获得需要的外网数据，然后转发回客户端。</p><p>反向代理：发生在服务端，用户请求时不知道代理的存在。</p><img src="/2024/11/08/Network-Linux/8cee5dc1a59ed7dda2507d3231435c4f.png" class="" title="img"><p>首先，在代理服务器上指定负载均衡规则。然后反向代理服务器会拦截指定域名或IP的请求，根据规则将请求分发到候选服务器上。要求候选服务器需要由容错机制（高可用方案），如主备模式，双主模式等</p></li></ul></li><li><p>四层负载均衡（基于IP地址和端口进行请求的转发）</p><ul><li><p>IP负载均衡</p><p>是在网络层修改请求目的地址实现负载均衡</p><img src="/2024/11/08/Network-Linux/3d77119f0badc8e410ab4762f6dc725a.png" class="" title="img"></li><li><p>MAC负载均衡</p><p>指通过修改mac地址实现负载均衡</p><img src="/2024/11/08/Network-Linux/c5a17700415024f2400fad5c33f08349.png" class="" title="img"></li></ul></li></ul></li></ul></blockquote><h2 id="Linux接收网络包的流程"><a href="#Linux接收网络包的流程" class="headerlink" title="Linux接收网络包的流程"></a>Linux接收网络包的流程</h2><p>网卡是计算机里的一个硬件，专门负责接收和发送网络包，当网卡接收到一个网络包后，会通过 DMA 技术，将网络包写入到指定的内存地址，也就是写入到 Ring Buffer ，这个是一个环形缓冲区，接着就会告诉操作系统这个网络包已经到达。</p><p>这个告诉操作系统的操作可以通过中断来实现，但在高性能网络场景下，可能会频繁触发中断，影响系统处理效率。</p><p>所以为了解决频繁中断带来的性能开销，Linux 内核在 2.6 版本中引入了 <strong>NAPI 机制</strong>，它是混合「中断和轮询」的方式来接收网络包，它的核心概念就是<strong>不采用中断的方式读取数据</strong>，而是首先采用中断唤醒数据接收的服务程序，然后 <code>poll</code> 的方法来轮询数据。</p><p>因此，当有网络包到达时，会通过 DMA 技术，将网络包写入到指定的内存地址，接着网卡向 CPU 发起硬件中断，当 CPU 收到硬件中断请求后，根据中断表，调用已经注册的中断处理函数。</p><p>硬件中断处理函数会做如下的事情：</p><ul><li>需要先「暂时屏蔽中断」，表示已经知道内存中有数据了，告诉网卡下次再收到数据包直接写内存就可以了，不要再通知 CPU 了，这样可以提高效率，避免 CPU 不停的被中断。</li><li>接着，发起「软中断」，然后恢复刚才屏蔽的中断。</li></ul><p>硬件中断处理函数做的事情很少，主要耗时的工作都交给软中断处理函数了。</p><p>内核中的 ksoftirqd 线程专门负责软中断的处理，当 ksoftirqd 内核线程收到软中断后，就会来轮询处理数据。</p><p>ksoftirqd 线程会从 Ring Buffer 中获取一个数据帧，用 sk_buff 表示，从而可以作为一个网络包交给网络协议栈进行逐层处理。</p><p>处理过程：</p><ol><li>网络接口层，会检查报文的合法性，若不合法则丢弃，合法会找到网络包的上层协议类型，如IPv4或IPv6，接着再去掉帧头和帧尾，交到网络层。</li><li>取出IP包，判断网络包下一步的走向，比如是交给上层处理还是转发出去。当确认这个网络包要发送给本机后，就会从 IP 头里看看上一层协议的类型是 TCP 还是 UDP，接着去掉 IP 头，然后交给传输层。</li><li>传输层，取出 TCP 头或 UDP 头，根据四元组「源 IP、源端口、目的 IP、目的端口」 作为标识，找出对应的 Socket，并把数据放到 Socket 的接收缓冲区。</li><li>Socket，应用层程序调用 Socket 接口，将内核的 Socket 接收缓冲区的数据「拷贝」到应用层的缓冲区，然后唤醒用户进程。</li></ol><p>可以从下图左边部分看到网络包接收的流程，右边部分刚好反过来，它是网络包发送的流程。</p><img src="/2024/11/08/Network-Linux/%E6%94%B6%E5%8F%91%E6%B5%81%E7%A8%8B.png" class="" title="img"><h2 id="Linux发送网络包的流程"><a href="#Linux发送网络包的流程" class="headerlink" title="Linux发送网络包的流程"></a>Linux发送网络包的流程</h2><p>整体流程可以见上图右侧，大概就是将接收流程反过来。</p><p>有一些需要注意的点：</p><ol><li><p>应用程序调用Socket发送数据包的接口时，由于是系统调用，会陷入内核态。内核会申请一个内核态的 sk_buff 内存，<strong>将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区</strong>。</p></li><li><p>若传输层使用TCP协议，则不能直接取出sk_buff，而是要先拷贝一个sk_buff副本。是因为当网卡发送完后，会将sk_buff释放，但TCP支持丢失重传，所以在收到ACK前，sk_buff的内容应该能读取。</p></li><li><p>当完成对整个数据包的封装后，会触发「软中断」告诉网卡驱动程序，这里有新的网络包需要发送，驱动程序会从发送队列中读取 sk_buff，将这个 sk_buff 挂到 RingBuffer 中，接着将 sk_buff 数据映射到网卡可访问的内存 DMA 区域，最后完成真实的发送。当发送完成的时候，网卡设备会触发一个硬中断来释放内存，主要是释放 sk_buff 内存和清理 RingBuffer 内存。最后，当收到这个 TCP 报文的 ACK 应答时，传输层就会释放原始的 sk_buff 。</p></li></ol><p>在发送网络数据的时候，涉及几次内存拷贝操作？</p><ol><li>调用发送数据的系统调用的时候，内核会申请一个内核态的 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区。</li><li>在使用 TCP 传输协议的情况下，从传输层进入网络层的时候，每一个 sk_buff 都会被克隆一个新的副本出来。副本 sk_buff 会被送往网络层，等它发送完的时候就会释放掉，然后原始的 sk_buff 还保留在传输层，目的是为了实现 TCP 的可靠传输，等收到这个数据包的 ACK 时，才会释放原始的 sk_buff 。</li><li>当 IP 层发现 sk_buff 大于 MTU 时才需要进行。会再申请额外的 sk_buff，并将原来的 sk_buff 拷贝为多个小的 sk_buff。</li></ol>]]></content>
    
    
    <categories>
      
      <category>Network</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Network</tag>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>OS-Memory</title>
    <link href="/2024/11/06/OS-Memory/"/>
    <url>/2024/11/06/OS-Memory/</url>
    
    <content type="html"><![CDATA[<h1 id="操作系统——分级缓存体系"><a href="#操作系统——分级缓存体系" class="headerlink" title="操作系统——分级缓存体系"></a>操作系统——分级缓存体系</h1><h2 id="存储器的层次结构"><a href="#存储器的层次结构" class="headerlink" title="存储器的层次结构"></a>存储器的层次结构</h2><ol><li>寄存器</li><li>Cache</li><li>内存</li><li>硬盘</li></ol><p>一个形象的比喻：</p><p>把CPU比作人类的大脑，脑中在思考的东西，就类似于CPU中的<strong>寄存器</strong>，处理速度最快，但能存储的东西很少。</p><p>脑中的记忆就类似于CPU Cache（CPU高速缓存），处理速度相比寄存器慢了一点，但能够存储的数据比寄存器多。CPU Cache会分成L1、L2、L3三层，其中L1 Cache包括【数据缓存】和【指令缓存】。主要区分为L1的读写速度快于L2、L3，存储空间更小。可以类比于脑中的短期记忆，L2、L3更类似于中长期记忆。</p><p>以上是CPU内部的存储器，下面再说说CPU外部的存储器：</p><p>假设我们在阅读，桌子上的书籍就相当于内存（内容是数据），而书架上的书可以类比为硬盘。</p><p>我们从书架取书到桌子上，阅读，脑中记忆，思考的一整个流程就相似于从磁盘加载数据到内存，再到CPU的寄存器和Cache中，最后供CPU进行计算。</p><h2 id="寄存器"><a href="#寄存器" class="headerlink" title="寄存器"></a>寄存器</h2><p>最靠近CPU的控制单元和计算单元，读取速度最快，故价格也最贵</p><ul><li><p>32 位 CPU 中大多数寄存器可以存储 <code>4</code> 个字节；</p></li><li><p>64 位 CPU 中大多数寄存器可以存储 <code>8</code> 个字节。</p></li></ul><p>寄存器的访问速度非常快，一般要求在半个 CPU 时钟周期内完成读写（CPU时钟周期是CPU主频的倒数）</p><h2 id="CPU-Cache"><a href="#CPU-Cache" class="headerlink" title="CPU Cache"></a>CPU Cache</h2><p>CPU Cache 用的是一种叫 <strong>SRAM</strong>（<strong>Static Random-Access Memory，静态随机存储器</strong>）的芯片</p><blockquote><p>静态指当有电时可以保存数据，断电后数据会丢失</p></blockquote><p>CPU 的高速缓存，通常可以分为 L1、L2、L3 这样的三层高速缓存</p><ul><li>L1高速缓存</li></ul><p>L1 高速缓存的访问速度几乎和寄存器一样快，通常只需要 <code>2~4</code> 个时钟周期</p><p>每个 CPU 核心都有一块属于自己的 L1 高速缓存，指令和数据在 L1 是分开存放的，所以 L1 高速缓存通常分成<strong>指令缓存</strong>和<strong>数据缓存</strong>。</p><ul><li>L2高速缓存</li></ul><p>L2 高速缓存同样每个 CPU 核心都有，但是 L2 高速缓存位置比 L1高速缓存距离 CPU 核心更远，访问速度通常在 <code>10~20</code> 个时钟周期。</p><ul><li>L3高速缓存</li></ul><p>L3 高速缓存通常是多个 CPU 核心共用的，位置比 L2 高速缓存距离 CPU 核心更远，访问速度相对也比较慢一些，访问速度在 <code>20~60</code>个时钟周期。</p><h2 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h2><p>内存使用的是 DRAM （<strong>Dynamic Random Access Memory，动态随机存取存储器</strong>）的芯片。相比 SRAM，DRAM 的密度更高，功耗更低，有更大的容量，而且造价比 SRAM 芯片便宜很多。</p><p>DRAM 存储一个 bit 数据，只需要一个晶体管和一个电容就能存储。但是因为数据会被存储在电容里，电容会不断漏电，所以需要「定时刷新」电容，才能保证数据不会被丢失，这就是 DRAM 之所以被称为「动态」存储器的原因，只有不断刷新，数据才能被存储起来。</p><p>DRAM 的数据访问电路和刷新电路都比 SRAM 更复杂，所以访问的速度会更慢，内存速度大概在 <code>200~300</code> 个 时钟周期之间。</p><h2 id="SSD-HDD-硬盘"><a href="#SSD-HDD-硬盘" class="headerlink" title="SSD&#x2F;HDD 硬盘"></a>SSD&#x2F;HDD 硬盘</h2><p>SSD（<em>Solid-state disk</em>） 就是我们常说的固体硬盘，结构和内存类似，但是它相比内存的优点是断电后数据还是存在的，而内存、寄存器、高速缓存断电后数据都会丢失。</p><p>机械硬盘（<em>Hard Disk Drive, HDD</em>），是通过物理读写的方式来访问数据的，访问速度很慢。</p><h2 id="CPU读写数据的方式"><a href="#CPU读写数据的方式" class="headerlink" title="CPU读写数据的方式"></a>CPU读写数据的方式</h2><p>CPU并不会直接和距离遥远的存储设备直接打交道，而是通过距离近的存储设备进行传递。</p><p>比如，CPU Cache 的数据是从内存加载过来的，写回数据的时候也只写回到内存，CPU Cache 不会直接把数据写到硬盘，也不会直接从硬盘加载数据，而是先加载到内存，再从内存加载到 CPU Cache 中。</p><p>访问数据也是同理，CPU会依次从访问速度快的存储设备查询到速度慢的存储设备。</p>]]></content>
    
    
    <categories>
      
      <category>OS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>OS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>learnMarkdown</title>
    <link href="/2024/09/26/learnMarkdown/"/>
    <url>/2024/09/26/learnMarkdown/</url>
    
    <content type="html"><![CDATA[<h1 id="第一篇博客，顺便学一下markdown语法"><a href="#第一篇博客，顺便学一下markdown语法" class="headerlink" title="第一篇博客，顺便学一下markdown语法"></a>第一篇博客，顺便学一下markdown语法</h1><h2 id="markdown简介"><a href="#markdown简介" class="headerlink" title="markdown简介"></a>markdown简介</h2><p>Markdown 是一种轻量级标记语言<br>Markdown 编写的文档后缀为 .md</p><!--more--><h2 id="markdown基本语法"><a href="#markdown基本语法" class="headerlink" title="markdown基本语法"></a>markdown基本语法</h2><h3 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h3><ul><li>使用#号标记，可以表示1-6级标题， 随#的个数递增，一级标题字号最大，六级标题字号最小。  </li><li>注意在井号和字符之间留一个空格</li></ul><h3 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h3><ul><li>星号与下划线是相同的效果，单是斜体，双是粗体，三是粗斜体</li><li>斜体： <em>这是斜体</em> <em>这是斜体</em></li><li>粗体： <strong>这是粗体</strong>  <strong>这是粗体</strong></li><li>粗斜体： <em><strong>这是粗斜体</strong></em> <em><strong>这是粗斜体</strong></em></li></ul><h3 id="换行"><a href="#换行" class="headerlink" title="换行"></a>换行</h3><p>markdown的换行有很多方式</p><ul><li>直接在一句话后加两个空格</li><li>两句话之间加一个空行</li><li>markdown支持内嵌html标签，可以通过<code>&lt;br/&gt;</code>来实现换行操作(转义字符&#96;，位于数字1的左边)</li></ul><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p>markdown中的引用通过符号<code>&gt;</code>实现<br>在引用的区块内，允许换行存在，换行并不会终止引用的区块。如果要结束引用，需要一行空白行，来结束引用的区块。</p><blockquote><p>这是一个引用</p><blockquote><p>二级引用</p></blockquote></blockquote><p>退出引用</p><h3 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h3><p>markdown中嵌入链接的方式：<br><code>[链接名称]</code> <code>(链接地址)</code><br>或用<code>&lt;链接地址&gt;</code><br><a href="https://lz2021211161.github.io/">这是刘正的博客</a></p><h3 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h3><p>markdown中嵌入图片的方式：<br><code>![图片描述，可写可不写，但是中括号要有](图片地址，本地链接或者URL地址。)</code>  </p><img src="/2024/09/26/learnMarkdown/d5763d758ae2569ae50b8c09fcb60077-1727330188634-2.png" class="" title="d5763d758ae2569ae50b8c09fcb60077"><h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3><p>列表分为有序列表和无序列表</p><ul><li><p>无序列表，使用*、+、-，再加一个空格作为列表的标记</p></li><li><p>有序列表，使用数字并加上.号，再加一个空格作为列表的标记</p><ul><li>子序列</li></ul></li></ul><ol><li>有序列表<ol><li>有序列表</li></ol></li><li>有序列表</li></ol><h3 id="分隔线"><a href="#分隔线" class="headerlink" title="分隔线"></a>分隔线</h3><p>Markdown中给出了多种分割线的样式，我们可以使用分割线让文章结构更加的清晰。<br>分割线的使用，可以在一行中用三个-or*来建立一个分割线，但是注意：在分割线的上面空一行！！！<br>分割线：  </p><hr><hr><p>注意：写分割线前，要空一行之后写，否则会导致前一行字体放大。</p><hr><h3 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a>删除线</h3><p>删除线的的使用，可以在要添加删除线的文字前后添加两个~<br><del>这是要被删除的文字</del></p><h3 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h3><p>在单行内引用代码直接使用反引号即可<br>多行引用代码，需要在代码块的前一行和后一行使用三个反引号，同时在前一个反引号后写入代码的语言  </p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br>   <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;HelloWorld&quot;</span>);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h3><p>表格使用|来分割不同的单元格，使用-来分隔表头和其他行</p><ul><li>:-：将表头及单元格内容左对齐</li><li>-:：将表头及单元格内容右对齐</li><li>:-:：将表头及单元格内容居中  <table><thead><tr><th>项目</th><th align="right">价格</th><th align="center">数量</th></tr></thead><tbody><tr><td>计算机</td><td align="right">$1600</td><td align="center">5</td></tr><tr><td>手机</td><td align="right">$12</td><td align="center">12</td></tr><tr><td>管线</td><td align="right">$1</td><td align="center">234</td></tr></tbody></table></li></ul><h3 id="脚注"><a href="#脚注" class="headerlink" title="脚注"></a>脚注</h3><p>脚注是对文本的备注</p><p>使用 Markdown<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="Markdown是一种纯文本标记语言">[1]</span></a></sup>可以效率的书写文档, 直接转换成 HTML<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="HyperText Markup Language 超文本标记语言">[2]</span></a></sup>, 你可以使用 Typora 编辑器进行书写。</p><blockquote><p>注意脚注会被自动搬运到最后面，需要到文档末尾查看，并且脚注后方的链接可以跳转回加注的地方</p></blockquote><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>Markdown是一种纯文本标记语言<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span>HyperText Markup Language 超文本标记语言<a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>语言</category>
      
    </categories>
    
    
    <tags>
      
      <tag>markdown</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2024/09/26/hello-world/"/>
    <url>/2024/09/26/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
